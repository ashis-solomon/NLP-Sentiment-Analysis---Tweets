{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "278849a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error retrieving https://api.twitter.com/2/search/adaptive.json?include_profile_interstitial_type=1&include_blocking=1&include_blocked_by=1&include_followed_by=1&include_want_retweets=1&include_mute_edge=1&include_can_dm=1&include_can_media_tag=1&skip_status=1&cards_platform=Web-12&include_cards=1&include_ext_alt_text=true&include_quote_count=true&include_reply_count=1&tweet_mode=extended&include_entities=true&include_user_entities=true&include_ext_media_color=true&include_ext_media_availability=true&send_error_codes=true&simple_quoted_tweets=true&q=since_id%3A1320246372008853503+max_id%3A1320246372008853504&tweet_search_mode=live&count=100&query_source=spelling_expansion_revert_click&pc=1&spelling_corrections=1&ext=mediaStats%2ChighlightedLabel: non-200 status code\n",
      "4 requests to https://api.twitter.com/2/search/adaptive.json?include_profile_interstitial_type=1&include_blocking=1&include_blocked_by=1&include_followed_by=1&include_want_retweets=1&include_mute_edge=1&include_can_dm=1&include_can_media_tag=1&skip_status=1&cards_platform=Web-12&include_cards=1&include_ext_alt_text=true&include_quote_count=true&include_reply_count=1&tweet_mode=extended&include_entities=true&include_user_entities=true&include_ext_media_color=true&include_ext_media_availability=true&send_error_codes=true&simple_quoted_tweets=true&q=since_id%3A1320246372008853503+max_id%3A1320246372008853504&tweet_search_mode=live&count=100&query_source=spelling_expansion_revert_click&pc=1&spelling_corrections=1&ext=mediaStats%2ChighlightedLabel failed, giving up.\n"
     ]
    },
    {
     "ename": "ScraperException",
     "evalue": "4 requests to https://api.twitter.com/2/search/adaptive.json?include_profile_interstitial_type=1&include_blocking=1&include_blocked_by=1&include_followed_by=1&include_want_retweets=1&include_mute_edge=1&include_can_dm=1&include_can_media_tag=1&skip_status=1&cards_platform=Web-12&include_cards=1&include_ext_alt_text=true&include_quote_count=true&include_reply_count=1&tweet_mode=extended&include_entities=true&include_user_entities=true&include_ext_media_color=true&include_ext_media_availability=true&send_error_codes=true&simple_quoted_tweets=true&q=since_id%3A1320246372008853503+max_id%3A1320246372008853504&tweet_search_mode=live&count=100&query_source=spelling_expansion_revert_click&pc=1&spelling_corrections=1&ext=mediaStats%2ChighlightedLabel failed, giving up.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mScraperException\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [23], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m tweets_list2 \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Using TwitterSearchScraper to scrape data and append tweets to list\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i,tweet \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(sntwitter\u001b[38;5;241m.\u001b[39mTwitterSearchScraper(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msince_id:1320246372008853503 max_id:1320246372008853504\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mget_items()):\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# for i,tweet in enumerate(sntwitter.TwitterSearchScraper('elon musk tesla since:2022-11-02 until:2022-11-22').get_items()):\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#     if i>100:\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#         break\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     tweets_list2\u001b[38;5;241m.\u001b[39mappend([tweet\u001b[38;5;241m.\u001b[39mdate, tweet\u001b[38;5;241m.\u001b[39mid, tweet\u001b[38;5;241m.\u001b[39mcontent, tweet\u001b[38;5;241m.\u001b[39murl, tweet\u001b[38;5;241m.\u001b[39muser\u001b[38;5;241m.\u001b[39musername, tweet\u001b[38;5;241m.\u001b[39mlikeCount, tweet\u001b[38;5;241m.\u001b[39mretweetCount, tweet\u001b[38;5;241m.\u001b[39mlang])\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/snscrape/modules/twitter.py:680\u001b[0m, in \u001b[0;36mTwitterSearchScraper.get_items\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    677\u001b[0m \t\u001b[38;5;28;01mdel\u001b[39;00m params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtweet_search_mode\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    678\u001b[0m \t\u001b[38;5;28;01mdel\u001b[39;00m paginationParams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtweet_search_mode\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m--> 680\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_api_data(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://api.twitter.com/2/search/adaptive.json\u001b[39m\u001b[38;5;124m'\u001b[39m, params, paginationParams, cursor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cursor):\n\u001b[1;32m    681\u001b[0m \t\u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_instructions_to_tweets(obj)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/snscrape/modules/twitter.py:369\u001b[0m, in \u001b[0;36m_TwitterAPIScraper._iter_api_data\u001b[0;34m(self, endpoint, params, paginationParams, cursor, direction)\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    368\u001b[0m \t_logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRetrieving scroll page \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcursor\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 369\u001b[0m \tobj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_api_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreqParams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    370\u001b[0m \t\u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m    372\u001b[0m \t\u001b[38;5;66;03m# No data format test, just a hard and loud crash if anything's wrong :-)\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/snscrape/modules/twitter.py:339\u001b[0m, in \u001b[0;36m_TwitterAPIScraper._get_api_data\u001b[0;34m(self, endpoint, params)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_api_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, endpoint, params):\n\u001b[1;32m    338\u001b[0m \t\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_guest_token()\n\u001b[0;32m--> 339\u001b[0m \tr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apiHeaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponseOkCallback\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_api_response\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    340\u001b[0m \t\u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    341\u001b[0m \t\tobj \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/snscrape/base.py:216\u001b[0m, in \u001b[0;36mScraper._get\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 216\u001b[0m \t\u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/snscrape/base.py:212\u001b[0m, in \u001b[0;36mScraper._request\u001b[0;34m(self, method, url, params, data, headers, timeout, responseOkCallback, allowRedirects)\u001b[0m\n\u001b[1;32m    210\u001b[0m \tmsg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retries \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requests to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreq\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m failed, giving up.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    211\u001b[0m \tlogger\u001b[38;5;241m.\u001b[39mfatal(msg)\n\u001b[0;32m--> 212\u001b[0m \t\u001b[38;5;28;01mraise\u001b[39;00m ScraperException(msg)\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReached unreachable code\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mScraperException\u001b[0m: 4 requests to https://api.twitter.com/2/search/adaptive.json?include_profile_interstitial_type=1&include_blocking=1&include_blocked_by=1&include_followed_by=1&include_want_retweets=1&include_mute_edge=1&include_can_dm=1&include_can_media_tag=1&skip_status=1&cards_platform=Web-12&include_cards=1&include_ext_alt_text=true&include_quote_count=true&include_reply_count=1&tweet_mode=extended&include_entities=true&include_user_entities=true&include_ext_media_color=true&include_ext_media_availability=true&send_error_codes=true&simple_quoted_tweets=true&q=since_id%3A1320246372008853503+max_id%3A1320246372008853504&tweet_search_mode=live&count=100&query_source=spelling_expansion_revert_click&pc=1&spelling_corrections=1&ext=mediaStats%2ChighlightedLabel failed, giving up."
     ]
    }
   ],
   "source": [
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas as pd\n",
    "\n",
    "# Creating list to append tweet data to\n",
    "tweets_list2 = []\n",
    "\n",
    "# Using TwitterSearchScraper to scrape data and append tweets to list\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('since_id:1320246372008853503 max_id:1320246372008853504').get_items()):\n",
    "# for i,tweet in enumerate(sntwitter.TwitterSearchScraper('elon musk tesla since:2022-11-02 until:2022-11-22').get_items()):\n",
    "#     if i>100:\n",
    "#         break\n",
    "    tweets_list2.append([tweet.date, tweet.id, tweet.content, tweet.url, tweet.user.username, tweet.likeCount, tweet.retweetCount, tweet.lang])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5756c31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe from the tweets list above\n",
    "tweets_df = pd.DataFrame(tweets_list2, columns=['datetime', 'tweet Id', 'text', 'url', 'username', 'likeCount', 'retweetCount', 'lang'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6df5cdeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>tweet Id</th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "      <th>username</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>retweetCount</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2018-08-17 15:41:55+00:00</td>\n",
       "      <td>1030479846454042626</td>\n",
       "      <td>In Kerala's chengannur\\na Christian family was...</td>\n",
       "      <td>https://twitter.com/mvmeet/status/103047984645...</td>\n",
       "      <td>mvmeet</td>\n",
       "      <td>2336</td>\n",
       "      <td>1515</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2018-08-18 03:40:33+00:00</td>\n",
       "      <td>1030660695220789249</td>\n",
       "      <td>\"Come out Bengaluru, Help Kerala, Kodagu\"\\n\\nI...</td>\n",
       "      <td>https://twitter.com/girishalva/status/10306606...</td>\n",
       "      <td>girishalva</td>\n",
       "      <td>95</td>\n",
       "      <td>94</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>2018-08-15 20:57:03+00:00</td>\n",
       "      <td>1029834376257986563</td>\n",
       "      <td>ഞങ്ങൾക്ക് ഒരു ആംബുലൻസും മിടുക്കന്മാരായ 7 ഹെവി ...</td>\n",
       "      <td>https://twitter.com/Jamsheedoffl/status/102983...</td>\n",
       "      <td>Jamsheedoffl</td>\n",
       "      <td>77</td>\n",
       "      <td>98</td>\n",
       "      <td>ml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-08-09 07:20:58+00:00</td>\n",
       "      <td>1159726246202187776</td>\n",
       "      <td>We can pray for Paris floods, but no one seems...</td>\n",
       "      <td>https://twitter.com/liberal_slayerr/status/115...</td>\n",
       "      <td>liberal_slayerr</td>\n",
       "      <td>33</td>\n",
       "      <td>8</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2018-08-18 10:27:51+00:00</td>\n",
       "      <td>1030763198478262272</td>\n",
       "      <td>Republic TV and https://t.co/6eW6wJmJ9r initia...</td>\n",
       "      <td>https://twitter.com/BhatSakal/status/103076319...</td>\n",
       "      <td>BhatSakal</td>\n",
       "      <td>28</td>\n",
       "      <td>6</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2018-08-17 07:52:57+00:00</td>\n",
       "      <td>1030361828591730690</td>\n",
       "      <td>Helpline &amp;amp; Locations for Help\\n#keralafloo...</td>\n",
       "      <td>https://twitter.com/dharmachandru/status/10303...</td>\n",
       "      <td>dharmachandru</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2018-08-17 07:52:08+00:00</td>\n",
       "      <td>1030361622836142081</td>\n",
       "      <td>Please help rescue 25 people at this location,...</td>\n",
       "      <td>https://twitter.com/AleyDinesh/status/10303616...</td>\n",
       "      <td>AleyDinesh</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2018-08-17 07:10:46+00:00</td>\n",
       "      <td>1030351212518854658</td>\n",
       "      <td>@dhanyarajendran is there any drop off locatio...</td>\n",
       "      <td>https://twitter.com/vijaygirija/status/1030351...</td>\n",
       "      <td>vijaygirija</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2018-08-17 07:04:53+00:00</td>\n",
       "      <td>1030349732290281473</td>\n",
       "      <td>@NDRFHQ @Shwkothari Pls HELP-\\nA friend Kuriac...</td>\n",
       "      <td>https://twitter.com/PahadiPundit/status/103034...</td>\n",
       "      <td>PahadiPundit</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>2018-08-15 18:40:50+00:00</td>\n",
       "      <td>1029800097914089472</td>\n",
       "      <td>People who need help please use hashtag #needh...</td>\n",
       "      <td>https://twitter.com/eddie_boho/status/10298000...</td>\n",
       "      <td>eddie_boho</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    datetime             tweet Id  \\\n",
       "33 2018-08-17 15:41:55+00:00  1030479846454042626   \n",
       "25 2018-08-18 03:40:33+00:00  1030660695220789249   \n",
       "62 2018-08-15 20:57:03+00:00  1029834376257986563   \n",
       "1  2019-08-09 07:20:58+00:00  1159726246202187776   \n",
       "18 2018-08-18 10:27:51+00:00  1030763198478262272   \n",
       "..                       ...                  ...   \n",
       "38 2018-08-17 07:52:57+00:00  1030361828591730690   \n",
       "39 2018-08-17 07:52:08+00:00  1030361622836142081   \n",
       "40 2018-08-17 07:10:46+00:00  1030351212518854658   \n",
       "41 2018-08-17 07:04:53+00:00  1030349732290281473   \n",
       "65 2018-08-15 18:40:50+00:00  1029800097914089472   \n",
       "\n",
       "                                                 text  \\\n",
       "33  In Kerala's chengannur\\na Christian family was...   \n",
       "25  \"Come out Bengaluru, Help Kerala, Kodagu\"\\n\\nI...   \n",
       "62  ഞങ്ങൾക്ക് ഒരു ആംബുലൻസും മിടുക്കന്മാരായ 7 ഹെവി ...   \n",
       "1   We can pray for Paris floods, but no one seems...   \n",
       "18  Republic TV and https://t.co/6eW6wJmJ9r initia...   \n",
       "..                                                ...   \n",
       "38  Helpline &amp; Locations for Help\\n#keralafloo...   \n",
       "39  Please help rescue 25 people at this location,...   \n",
       "40  @dhanyarajendran is there any drop off locatio...   \n",
       "41  @NDRFHQ @Shwkothari Pls HELP-\\nA friend Kuriac...   \n",
       "65  People who need help please use hashtag #needh...   \n",
       "\n",
       "                                                  url         username  \\\n",
       "33  https://twitter.com/mvmeet/status/103047984645...           mvmeet   \n",
       "25  https://twitter.com/girishalva/status/10306606...       girishalva   \n",
       "62  https://twitter.com/Jamsheedoffl/status/102983...     Jamsheedoffl   \n",
       "1   https://twitter.com/liberal_slayerr/status/115...  liberal_slayerr   \n",
       "18  https://twitter.com/BhatSakal/status/103076319...        BhatSakal   \n",
       "..                                                ...              ...   \n",
       "38  https://twitter.com/dharmachandru/status/10303...    dharmachandru   \n",
       "39  https://twitter.com/AleyDinesh/status/10303616...       AleyDinesh   \n",
       "40  https://twitter.com/vijaygirija/status/1030351...      vijaygirija   \n",
       "41  https://twitter.com/PahadiPundit/status/103034...     PahadiPundit   \n",
       "65  https://twitter.com/eddie_boho/status/10298000...       eddie_boho   \n",
       "\n",
       "    likeCount  retweetCount lang  \n",
       "33       2336          1515   en  \n",
       "25         95            94   en  \n",
       "62         77            98   ml  \n",
       "1          33             8   en  \n",
       "18         28             6   en  \n",
       "..        ...           ...  ...  \n",
       "38          0             2   en  \n",
       "39          0             0   en  \n",
       "40          0             0   en  \n",
       "41          0             0   en  \n",
       "65          0             0   en  \n",
       "\n",
       "[66 rows x 8 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df = tweets_df.sort_values(by='likeCount', ascending=False)\n",
    "tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a1e366bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2558f217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Come out Bengaluru, Help Kerala, Kodagu\"\\n\\nIn Phase 2, #SOSKerala #SOSKodagu team is encouraging every Bengalurean to come out of the house &amp; help collect or donate relief material for flood victims.\\n\\n1) You can JOIN teams active in ur location\\n2) You can DONATE items required\\n\\n1 https://t.co/bQbcylxVfa'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df['text'][25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b663bb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "# from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "# from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3aae11cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mvader_lexicon\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('vader_lexicon')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93msentiment/vader_lexicon.zip/vader_lexicon/vader_lexicon.txt\u001b[0m\n\n  Searched in:\n    - '/home/ashis-solomon/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sia \u001b[39m=\u001b[39m SentimentIntensityAnalyzer()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/nltk/sentiment/vader.py:340\u001b[0m, in \u001b[0;36mSentimentIntensityAnalyzer.__init__\u001b[0;34m(self, lexicon_file)\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m    337\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    338\u001b[0m     lexicon_file\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msentiment/vader_lexicon.zip/vader_lexicon/vader_lexicon.txt\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    339\u001b[0m ):\n\u001b[0;32m--> 340\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlexicon_file \u001b[39m=\u001b[39m nltk\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mload(lexicon_file)\n\u001b[1;32m    341\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlexicon \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_lex_dict()\n\u001b[1;32m    342\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconstants \u001b[39m=\u001b[39m VaderConstants()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/nltk/data.py:750\u001b[0m, in \u001b[0;36mload\u001b[0;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[1;32m    747\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m<<Loading \u001b[39m\u001b[39m{\u001b[39;00mresource_url\u001b[39m}\u001b[39;00m\u001b[39m>>\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    749\u001b[0m \u001b[39m# Load the resource.\u001b[39;00m\n\u001b[0;32m--> 750\u001b[0m opened_resource \u001b[39m=\u001b[39m _open(resource_url)\n\u001b[1;32m    752\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mformat\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraw\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    753\u001b[0m     resource_val \u001b[39m=\u001b[39m opened_resource\u001b[39m.\u001b[39mread()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/nltk/data.py:876\u001b[0m, in \u001b[0;36m_open\u001b[0;34m(resource_url)\u001b[0m\n\u001b[1;32m    873\u001b[0m protocol, path_ \u001b[39m=\u001b[39m split_resource_url(resource_url)\n\u001b[1;32m    875\u001b[0m \u001b[39mif\u001b[39;00m protocol \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m protocol\u001b[39m.\u001b[39mlower() \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mnltk\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 876\u001b[0m     \u001b[39mreturn\u001b[39;00m find(path_, path \u001b[39m+\u001b[39;49m [\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m])\u001b[39m.\u001b[39mopen()\n\u001b[1;32m    877\u001b[0m \u001b[39melif\u001b[39;00m protocol\u001b[39m.\u001b[39mlower() \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mfile\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    878\u001b[0m     \u001b[39m# urllib might not use mode='rb', so handle this one ourselves:\u001b[39;00m\n\u001b[1;32m    879\u001b[0m     \u001b[39mreturn\u001b[39;00m find(path_, [\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m])\u001b[39m.\u001b[39mopen()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/nltk/data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    581\u001b[0m sep \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m*\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m*\u001b[39m \u001b[39m70\u001b[39m\n\u001b[1;32m    582\u001b[0m resource_not_found \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00msep\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mmsg\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00msep\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 583\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mvader_lexicon\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('vader_lexicon')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93msentiment/vader_lexicon.zip/vader_lexicon/vader_lexicon.txt\u001b[0m\n\n  Searched in:\n    - '/home/ashis-solomon/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "sia = SentimentIntensityAnalyzer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "949c9a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Something went wrong, but don’t fret — let’s give it another shot.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11704/1633949286.py:8: RuntimeWarning: coroutine 'HTML.arender' was never awaited\n",
      "  r.html.arender(sleep=2)\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "from requests_html import HTMLSession\n",
    "from requests_html import AsyncHTMLSession\n",
    "\n",
    "session = AsyncHTMLSession()\n",
    "url = \"https://twitter.com/user/status/1414963866304458758\"\n",
    "\n",
    "r = await session.get(url)\n",
    "r.html.arender(sleep=2)\n",
    "\n",
    "tweet_text = r.html.find('.css-901oao', first=True)\n",
    "\n",
    "print(tweet_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1260626",
   "metadata": {},
   "outputs": [],
   "source": [
    "<span class=\"css-901oao css-16my406 r-poiln3 r-bcqeeo r-qvutc0\">We've just launched a Person Finder instance to help track missing persons for the </span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
